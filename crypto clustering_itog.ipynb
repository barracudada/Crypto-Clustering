{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93dbf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rh/7rjcc_rs68n6wjb41vhqg3dh0000gn/T/ipykernel_86232/2111625055.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from src.detect_peaks import detect_peaks\n",
    "#from src.utils import *\n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#импорт необходимых библиотек\n",
    "import yfinance as yf\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "\n",
    "import requests\n",
    "\n",
    "import pandas_datareader as pd_reader\n",
    "\n",
    "import tsfel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c2453",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------------------------------------------- ##  \n",
    "# Задание 1\n",
    "## ----------------------------------------------------------------------------------------------- ##  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0dbac6",
   "metadata": {},
   "source": [
    "1) Получаем данные\n",
    "\n",
    "2) Определяем количество кластеров\n",
    "\n",
    "3) Проводим нормализацию\n",
    "\n",
    "4) Проводим кластеризацию методом Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269cc5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get TOP 100 crypto \n",
    "url = 'https://coin360.com/coin'\n",
    "r = requests.get(url)\n",
    "crypto = pd.read_html(r.text)\n",
    "\n",
    "crypto = list(crypto[0]['Symbol'])\n",
    "\n",
    "for i in range(len(crypto)):\n",
    "    crypto[i] = crypto[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246c1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem = []\n",
    "\n",
    "rem.append('wbnb')\n",
    "rem.append('xcn')\n",
    "rem.append('bttc')\n",
    "rem.append('iota')\n",
    "rem.append('bnx')\n",
    "rem.append('wemix')\n",
    "\n",
    "for i in rem:\n",
    "    crypto.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47b5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect data\n",
    "\n",
    "import cryptocompare as cc\n",
    "import datetime\n",
    "\n",
    "def get_minute_data(date=datetime.datetime.now()):\n",
    "    coins_df = []\n",
    "    try:\n",
    "        for i in crypto:\n",
    "            x = cc.get_historical_price_minute(i, currency='USD', limit=1440, toTs=date)\n",
    "            x = pd.DataFrame(x).fillna(method='ffill')\n",
    "            x = x.drop(columns=['conversionSymbol', 'conversionType', 'volumefrom'], errors='ignore')\n",
    "            x['time'] = pd.to_datetime(x['time'],unit='s')\n",
    "            x['ticker'] = i\n",
    "            x = np.array(x)\n",
    "            coins_df.append(x)\n",
    "        return(np.array(coins_df))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def get_week_data(date=datetime.datetime.now()):\n",
    "    coins_df = []\n",
    "    try:\n",
    "        for i in crypto:\n",
    "            x = cc.get_historical_price_hour(i, currency='USD', limit=168, toTs=date)\n",
    "            x = pd.DataFrame(x).fillna(method='ffill')\n",
    "            x = x.drop(columns=['conversionSymbol', 'conversionType', 'volumefrom'], errors='ignore')\n",
    "            x['time'] = pd.to_datetime(x['time'],unit='s')\n",
    "            x['ticker'] = i\n",
    "            x = np.array(x)\n",
    "            coins_df.append(x)\n",
    "        return(np.array(coins_df))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def get_day_data(date=datetime.datetime.now()):\n",
    "    coins_df = []\n",
    "    try:\n",
    "        for i in crypto:\n",
    "            x = cc.get_historical_price_day(i, currency='USD', limit=60, toTs=date)\n",
    "            x = pd.DataFrame(x).fillna(method='ffill')\n",
    "            x = x.drop(columns=['conversionSymbol', 'conversionType', 'volumefrom'], errors='ignore')\n",
    "            x['time'] = pd.to_datetime(x['time'],unit='s')\n",
    "            x['ticker'] = i\n",
    "            x = np.array(x)\n",
    "            coins_df.append(x)\n",
    "        coins_df = np.array(coins_df)\n",
    "        return(np.array(coins_df))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43127242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CCCAGG market does not exist for this coin pair (GMX-USD)\n",
      "[ERROR] CCCAGG market does not exist for this coin pair (GMX-USD)\n",
      "[ERROR] CCCAGG market does not exist for this coin pair (GMX-USD)\n"
     ]
    }
   ],
   "source": [
    "minutes = get_minute_data()\n",
    "weeks = get_week_data()\n",
    "days = get_day_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f63283",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [minutes, weeks, days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c41e4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fromatting and normalisation \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def formatting_and_norm(dttm, norm=1):\n",
    "    new_min = []\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    if norm == 1:\n",
    "        for i in range(len(dttm)):\n",
    "            coin = pd.DataFrame(dttm[i])\n",
    "            coin.set_index([0], inplace=True)\n",
    "            coin = coin.T[:-1]\n",
    "            coin = np.array(coin)\n",
    "            coin = min_max_scaler.fit_transform(coin)\n",
    "            new_min.append(coin)\n",
    "    else:\n",
    "        for i in range(len(dttm)):\n",
    "            coin = pd.DataFrame(dttm[i])\n",
    "            coin.set_index([0], inplace=True)\n",
    "            coin = coin.T[:-1]\n",
    "            coin = np.array(coin)\n",
    "            new_min.append(coin)\n",
    "    return(np.array(new_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c23044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Means clustering \n",
    "\n",
    "def clustr(dttm, k_range):\n",
    "\n",
    "    distortions = []\n",
    "    K = k_range\n",
    "    \n",
    "    appended = pd.DataFrame()\n",
    "    for i in formatting_and_norm(dttm):\n",
    "        appended = pd.concat([appended, pd.DataFrame(i)])\n",
    "  \n",
    "\n",
    "    for k in tqdm(K):\n",
    "        kmeanModel = KMeans(n_clusters=k)\n",
    "        kmeanModel.fit(appended)\n",
    "        distortions.append(kmeanModel.inertia_)\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(K, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad503c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclustr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminutes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mclustr\u001b[0;34m(dttm, k_range)\u001b[0m\n\u001b[1;32m      6\u001b[0m K \u001b[38;5;241m=\u001b[39m k_range\n\u001b[1;32m      8\u001b[0m appended \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mformatting_and_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdttm\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     10\u001b[0m     appended \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([appended, pd\u001b[38;5;241m.\u001b[39mDataFrame(i)])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tqdm(K):\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mformatting_and_norm\u001b[0;34m(dttm, norm)\u001b[0m\n\u001b[1;32m      7\u001b[0m min_max_scaler \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mMinMaxScaler()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdttm\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     10\u001b[0m         coin \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dttm[i])\n\u001b[1;32m     11\u001b[0m         coin\u001b[38;5;241m.\u001b[39mset_index([\u001b[38;5;241m0\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "clustr(minutes, range(2,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d263e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustr(days, range(2,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e206746",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustr(weeks, range(2,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a8f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appended_df(dttm):\n",
    "    appended = pd.DataFrame()\n",
    "    for i in formatting_and_norm(dttm, 1):\n",
    "        appended = pd.concat([appended, pd.DataFrame(i)])\n",
    "    return(appended)\n",
    "\n",
    "def appended_df_no_norm(dttm):\n",
    "    appended = pd.DataFrame()\n",
    "    for i in formatting_and_norm(dttm, 0):\n",
    "        appended = pd.concat([appended, pd.DataFrame(i)])\n",
    "    return(appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c14f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans, silhouette_score\n",
    "\n",
    "def kmeans(dttm, n=10, form=1):\n",
    "    \n",
    "    appended = pd.DataFrame()\n",
    "    for i in formatting_and_norm(dttm, form):\n",
    "        appended = pd.concat([appended, pd.DataFrame(i)])\n",
    "  \n",
    "    \n",
    "    distortions = []\n",
    "    silhouette = []\n",
    "    K = range(2, n)\n",
    "    for k in tqdm(K):\n",
    "        kmeanModel = TimeSeriesKMeans(n_clusters=k, metric=\"euclidean\", n_jobs=6, max_iter=10, n_init=5)\n",
    "        kmeanModel.fit(appended)\n",
    "        distortions.append(kmeanModel.inertia_)\n",
    "        silhouette.append(silhouette_score(appended, kmeanModel.labels_, metric=\"euclidean\"))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(K, distortions, 'b-')\n",
    "    ax2.plot(K, silhouette, 'r-')\n",
    "\n",
    "    ax1.set_xlabel('# clusters')\n",
    "    ax1.set_ylabel('Distortion', color='b')\n",
    "    ax2.set_ylabel('Silhouette', color='r')\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans(minutes), kmeans(days), kmeans(weeks)\n",
    "kmeans(minutes, 10, 0), kmeans(days, 10, 0), kmeans(weeks, 10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d2c5e",
   "metadata": {},
   "source": [
    "**Имеем:**\n",
    "\n",
    "С нормировкой:\n",
    "\n",
    "Для минутных данных - 3 кластера\n",
    "\n",
    "Для дневных данных - 3 кластера\n",
    "\n",
    "Для недельных данных - 3 кластера\n",
    "\n",
    "Без нормировки:\n",
    "\n",
    "Для минутных данных - 3 кластера\n",
    "\n",
    "Для дневных данных - 3 кластера\n",
    "\n",
    "Для недельных данных - 3 кластера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaec2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_show(dttm, n_clusters=3, form=1):\n",
    "    ts_kmeans = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", n_jobs=10, max_iter=10)\n",
    "    if form == 1:\n",
    "        ts_kmeans.fit(appended_df(dttm))\n",
    "    else:\n",
    "        ts_kmeans.fit(appended_df_no_norm(dttm))\n",
    "\n",
    "    for cluster_number in range(n_clusters):\n",
    "        plt.plot(ts_kmeans.cluster_centers_[cluster_number, :, 0].T, label=cluster_number)\n",
    "    plt.title(\"Cluster centroids\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2afcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_show(minutes, 3), clusters_show(days, 6), clusters_show(weeks, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a2bf0",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------------------------------------------- ##  \n",
    "# Задание 2\n",
    "## ----------------------------------------------------------------------------------------------- ##  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231744f3",
   "metadata": {},
   "source": [
    "А) Используем данные с прошлого д/з  \n",
    "\n",
    "Б) Пробуем tsfresh, tsfel  \n",
    "\n",
    "В) Применяем k-means ( нужно передать feature matrix на вход k-means)  \n",
    "\n",
    "Г) Визуализируем результат  \n",
    "\n",
    "Д) Пишем сравнительный анализ с фич экстрактором и без него (5 - 10 предложений)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return(df[indices_to_keep].astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842fa42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "\n",
    "def prep_for_fresh(df):\n",
    "    appended = pd.DataFrame()\n",
    "    for i, x in enumerate(df):\n",
    "        x = pd.DataFrame(x)\n",
    "        x = x.rename(columns={0: 'time', 1: 'price1', 2: 'price2', 3: 'price3', 4: 'price4', 5: 'price5', 6: 'name'})\n",
    "        x = x.drop(['time'], axis=1)\n",
    "        try:\n",
    "            x = x.drop(['name'], axis=1)\n",
    "        except:\n",
    "            pass\n",
    "        x = x.astype('float')\n",
    "        x['time'] = list(range(0, len(x)))\n",
    "        x['coin'] = i\n",
    "        appended = pd.concat([appended, x])\n",
    "    return(appended)\n",
    "\n",
    "def features(dttm):\n",
    "    new_prices_scaled_tsfresh_allf = extract_features(prep_for_fresh(dttm), \n",
    "                                                      column_id = \"coin\", \n",
    "                                                      column_sort = \"time\")\n",
    "    df = new_prices_scaled_tsfresh_allf.dropna(axis='columns')\n",
    "    df = clean_dataset(df)\n",
    "    K = range(2,15)\n",
    "    distortions = []\n",
    "    for k in tqdm(K):\n",
    "        kmeanModel = KMeans(n_clusters=k)\n",
    "        kmeanModel.fit(df)\n",
    "        distortions.append(kmeanModel.inertia_)\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(K, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cbaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features(minutes), features(weeks), features(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#отдельно сформируем функцию для вывода фичей из tsfel\n",
    "\n",
    "import tsfel\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# библиотека tsfel\n",
    "def get_tsfel_features(dttm):\n",
    "    cfg_file = tsfel.get_features_by_domain('spectral')\n",
    "    tsfel_data = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(dttm)):\n",
    "        x = pd.DataFrame(minutes[i])[[1,2,3,4,5]]\n",
    "        print(i)\n",
    "        new = tsfel.time_series_features_extractor(cfg_file, x, fs= 100)\n",
    "        clear_output(wait=True)\n",
    "        tsfel_data = pd.concat([tsfel_data, new])\n",
    "\n",
    "    tsfel_data = tsfel_data.reset_index(drop=True).dropna(axis='columns')\n",
    "    return(tsfel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a660102",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,11))\n",
    "plt.tight_layout(pad=5.0)\n",
    "\n",
    "#визуализация k-NN без предобработки\n",
    "plt.subplot(4,1,1)\n",
    "\n",
    "ts_kmeans = TimeSeriesKMeans(n_clusters=3, metric=\"euclidean\", n_jobs=10, max_iter=10)\n",
    "ts_kmeans.fit(appended_df_no_norm(minutes)[::5].reset_index(drop=True).T)\n",
    "\n",
    "for cluster_number in range(3):\n",
    "    plt.plot(pd.DataFrame(ts_kmeans.cluster_centers_[cluster_number]), label = cluster_number)\n",
    "\n",
    "plt.xlabel('Currency',  fontsize = 20)\n",
    "plt.ylabel('Distance to cluster', color='b',  fontsize = 20)\n",
    "plt.title('without_extraction_raw_data', fontsize = 20)\n",
    "\n",
    "\n",
    "#визуализация k-NN с нормализацией \n",
    "plt.subplot(4,1,2)\n",
    "\n",
    "ts_kmeans = TimeSeriesKMeans(n_clusters=3, metric=\"euclidean\", n_jobs=10, max_iter=10)\n",
    "ts_kmeans.fit(appended_df(minutes)[::5].reset_index(drop=True).T)\n",
    "\n",
    "for cluster_number in range(3):\n",
    "    plt.plot(pd.DataFrame(ts_kmeans.cluster_centers_[cluster_number]), label = cluster_number)\n",
    "\n",
    "plt.xlabel('Currency',  fontsize = 20)\n",
    "plt.ylabel('Distance to cluster', color='b',  fontsize = 20)\n",
    "plt.title('without_extraction_normalised_data', fontsize = 20)\n",
    "\n",
    "\n",
    "#визуализация кластеров после обработки tsfresh\n",
    "plt.subplot(4,1,3)\n",
    "\n",
    "df = extract_features(prep_for_fresh(minutes), column_id = \"coin\", column_sort = \"time\")\n",
    "df = df.dropna(axis='columns')\n",
    "\n",
    "ts_kmeans = TimeSeriesKMeans(n_clusters=3, metric=\"euclidean\", n_jobs=10, max_iter=10)\n",
    "ts_kmeans.fit(df.T)\n",
    "\n",
    "for cluster_number in range(3):\n",
    "    plt.plot(pd.DataFrame(ts_kmeans.cluster_centers_[cluster_number]), label = cluster_number)\n",
    "\n",
    "plt.xlabel('Currency',  fontsize = 20)\n",
    "plt.ylabel('Distance to cluster', color='b',  fontsize = 20)    \n",
    "plt.title('after_tsfresh_extraction', fontsize = 20)\n",
    "\n",
    "\n",
    "#визуализация кластеров после обработки tsfel\n",
    "plt.subplot(4,1,4)\n",
    "\n",
    "ts_kmeans = TimeSeriesKMeans(n_clusters=3, metric=\"euclidean\", n_jobs=10, max_iter=10)\n",
    "ts_kmeans.fit(get_tsfel_features(minutes).T)\n",
    "\n",
    "for cluster_number in range(3):\n",
    "    plt.plot(pd.DataFrame(ts_kmeans.cluster_centers_[cluster_number]), label = cluster_number)\n",
    "\n",
    "plt.xlabel('Currency',  fontsize = 20)\n",
    "plt.ylabel('Distance to cluster', color='b',  fontsize = 20)    \n",
    "plt.title('after_tsfel_extraction', fontsize = 20)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b372c",
   "metadata": {},
   "source": [
    "**Сравнительный анализ:**\n",
    "    \n",
    "1) При кластеризации сырых данных не видно явное присутсвие других кластеров. \n",
    "Можно сказать, что применение кластеризации к сырым данным не имеет смысла.\n",
    "\n",
    "2) Примение кластеризации к нормированным данным уже позволяет выделить существенные группы валют. \n",
    "Но есть предположение, что при нормализации данных MinMaxScaller валюты кластеризовались относительно своих цен, а не трендов.\n",
    "\n",
    "3) Кластеризация с использованием фич-экстракторов на первый взгляд слабо отличается друг от друга. \n",
    "На вход подавались сырые данные. Необходимо проверить методы с использованием нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88118de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_tsfresh(dttm):\n",
    "    x = prep_for_fresh(dttm)\n",
    "    x = extract_features(x, column_id = \"coin\", column_sort = \"time\")\n",
    "\n",
    "    #time, coin = list(x['time']), list(x['coin'])\n",
    "    #x = x[['price1', 'price2', 'price3', 'price4', 'price5']]\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    x = pd.DataFrame(min_max_scaler.fit_transform(x))\n",
    "    #x = x.rename(columns={0: 'time', 1: 'price1', 2: 'price2', 3: 'price3', 4: 'price4'})\n",
    "    #x['time'] = time\n",
    "    #x['coin'] = coin\n",
    "    return(x)\n",
    "\n",
    "def re_tsfel(dttm):\n",
    "    x = get_tsfel_features(dttm)\n",
    "    x = clean_dataset(x.dropna(axis='columns'))\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x = pd.DataFrame(min_max_scaler.fit_transform(x))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#визуализация кластеров после обработки tsfresh и нормализации\n",
    "plt.figure(figsize=(18,11))\n",
    "plt.subplot(2,1,1)\n",
    "\n",
    "#df = extract_features(re_tsfresh(minutes), column_id = \"coin\", column_sort = \"time\")\n",
    "#df = df.dropna(axis='columns')\n",
    "#df = df.drop(columns=['time', 'coin'])\n",
    "\n",
    "ts_kmeans = TimeSeriesKMeans(n_clusters=3, metric=\"euclidean\", n_jobs=10, max_iter=10)\n",
    "ts_kmeans.fit(re_tsfresh(minutes).T)\n",
    "\n",
    "for cluster_number in range(3):\n",
    "    plt.plot(pd.DataFrame(ts_kmeans.cluster_centers_[cluster_number]), label = cluster_number)\n",
    "\n",
    "plt.xlabel('Currency',  fontsize = 20)\n",
    "plt.ylabel('Distance to cluster', color='b',  fontsize = 20)    \n",
    "plt.title('after_tsfresh_extraction_and_norm', fontsize = 20)\n",
    "\n",
    "\n",
    "#визуализация кластеров после обработки tsfel и нормализации\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "plt.tight_layout(pad=8.0)\n",
    "\n",
    "\n",
    "ts_kmeans = TimeSeriesKMeans(n_clusters=3, metric=\"euclidean\", n_jobs=10, max_iter=10)\n",
    "ts_kmeans.fit(re_tsfel(minutes).T)\n",
    "\n",
    "for cluster_number in range(3):\n",
    "    plt.plot(pd.DataFrame(ts_kmeans.cluster_centers_[cluster_number]), label = cluster_number)\n",
    "\n",
    "plt.xlabel('Currency',  fontsize = 20)\n",
    "plt.ylabel('Distance to cluster', color='b',  fontsize = 20)    \n",
    "plt.title('after_tsfel_extraction_and_norm', fontsize = 20)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91ade7",
   "metadata": {},
   "source": [
    "**Сравнительный анализ:**\n",
    "    \n",
    "1) Кластеризация после tsfresh и нормализации плохо отражена из-за масштаба. \n",
    "На промежутках, где нет пиков - расстояние до центров кластеров, как будто, одинаковое для всех монет. \n",
    "Плохое качество клстеризации.\n",
    "\n",
    "2) TSFEL показал результаты лучше - кластеры выделились однозначно. \n",
    "Визуально понятно, к какому кластеру относится та или иная валюта. \n",
    "Расстояния хорошо представими."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a06a151",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------------------------------------------- ##  \n",
    "# Задание 3\n",
    "## ----------------------------------------------------------------------------------------------- ##  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961588a7",
   "metadata": {},
   "source": [
    "А) Используем данные с прошлого д/з  \n",
    "\n",
    "Б) Применяем DTW, визуализируем  \n",
    "\n",
    "В) Применяем иерархический DTW, визуализируем  \n",
    "\n",
    "Г) Пишем сравнительные анализ иерархического и нормального DTW. Чем отличаются методы?  \n",
    "\n",
    "Д) Что такое DTW distance? Как оно рассчитывается?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0384e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "ts_kmeans_dtw = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", n_jobs=6, max_iter=10)\n",
    "ts_kmeans_dtw.fit(re_tsfresh(minutes).T)\n",
    "\n",
    "for cluster_number in range(n_clusters):\n",
    "    plt.plot(ts_kmeans_dtw.cluster_centers_[cluster_number, :, 0].T, label=cluster_number)\n",
    "plt.title(\"Cluster centroids\",  fontsize = 20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19563218",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "ts_kmeans_dtw = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", n_jobs=6, max_iter=10)\n",
    "ts_kmeans_dtw.fit(re_tsfel(minutes).T)\n",
    "\n",
    "for cluster_number in range(n_clusters):\n",
    "    plt.plot(ts_kmeans_dtw.cluster_centers_[cluster_number, :, 0].T, label=cluster_number)\n",
    "plt.title(\"Cluster centroids\",  fontsize = 20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# иерархический dtw\n",
    "\n",
    "# Custom Hierarchical clustering\n",
    "plt.figure(figsize=(18,11))\n",
    "plt.subplot(4,1,1)\n",
    "\n",
    "model1 = clustering.Hierarchical(dtw.distance_matrix_fast, {})\n",
    "cluster_idx = model1.fit(new_prices_scaled)\n",
    "shc.dendrogram(cluster_idx)\n",
    "\n",
    "\n",
    "# Keep track of full tree by using the HierarchicalTree wrapper class\n",
    "plt.subplot(4,1,2)\n",
    "model2 = clustering.HierarchicalTree(model1)\n",
    "cluster_idx = model2.fit(new_prices_scaled)\n",
    "shc.dendrogram(cluster_idx)\n",
    "\n",
    "# You can also pass keyword arguments identical to instantiate a Hierarchical object\n",
    "plt.subplot(4,1,3)\n",
    "model2 = clustering.HierarchicalTree(dists_fun=dtw.distance_matrix_fast, dists_options={})\n",
    "cluster_idx = model2.fit(new_prices_scaled)\n",
    "shc.dendrogram(cluster_idx)\n",
    "\n",
    "# SciPy linkage clustering\n",
    "plt.subplot(4,1,4)\n",
    "dtw_cluster = clustering.LinkageTree(dtw.distance_matrix_fast, {})\n",
    "cluster_idx = dtw_cluster.fit(new_prices_scaled)\n",
    "shc.dendrogram(cluster_idx)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72cac8b",
   "metadata": {},
   "source": [
    "Что такое DTW distance?  \n",
    "украл из леции:  \n",
    "$$DTW(x, y) = min_{\\pi} \\sqrt{\\sum_{(i,j)\\in \\pi} d(x_i, y_j)^2},$$\n",
    "\n",
    "где $\\pi = [\\pi_0, ..., \\pi_K]$ - это путь, удовлетворяющий набору условий:\n",
    "- это лист парных индексов $\\pi_k = (i_k, j_k)$, где  $0\\leq i_k < n$ и $0\\leq j_k < m$\n",
    "- $\\pi_0 = (0, 0)$ и $\\pi_K = (n-1, m-1)$\n",
    "- для всех $k>0$, $\\pi_k=(i_k, j_k)$ и $\\pi_{k-1}=(i_{k-1}, j_{k-1})$ удовлетворяют следующим неравенствам:\n",
    "    - $i_{k-1} \\leq i_k \\leq i_{k-1} + 1$\n",
    "    - $j_{j-1} \\leq j_k \\leq j_{k-1} + 1$  \n",
    "      \n",
    "Своими словами:  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
